{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的问候:\n",
      "您好，我是AI助手，我代表公司感谢您对我们的支持与信任。关于您的使用体验，希望您可以从以下几个方面进行分享：1）使用过程中是否顺畅、便捷；2）产品或服务是否满足您的需求；3）遇到问题时，我们的客服团队是否及时有效地帮助您解决。您的意见和建议对我们非常重要，可以帮助我们不断改进和提升。期待您的回复，再次感谢！\n",
      "小明提供的反馈:\n",
      "我觉得这个服务很好，界面友好，使用方便！\n",
      "模型对用户反馈的回复:\n",
      "非常感谢您的反馈，小明！我们很高兴听到您对我们的服务感到满意，特别是对于界面友好和使用方便的评价。我们将继续努力，提供更好的服务和用户体验。如果您有任何其他建议或需求，请随时告诉我们，我们非常乐意为您服务！\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chat_models import ChatTongyi\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 初始化聊天模型\n",
    "chat = ChatTongyi(\n",
    "    model='qwen-plus',\n",
    "    top_p=0.9,\n",
    "    temperature=0.9,\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "# 创建部分提示模板\n",
    "partial_prompt = PromptTemplate(\n",
    "    template=\"{greeting} {name}，我们很高兴您使用我们的服务。请您分享一下您的使用体验如何？\",\n",
    "    input_variables=[\"name\"],\n",
    "    partial_variables={\"greeting\": \"亲爱的用户\"}\n",
    ")\n",
    "\n",
    "# 格式化提示\n",
    "input_name = \"小明\"\n",
    "formatted_prompt = partial_prompt.format(name=input_name)\n",
    "\n",
    "# 将格式化后的提示包装为 HumanMessage，并传递给 chat()\n",
    "response = chat([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "# 打印模型的初始回复\n",
    "print(\"模型的问候:\")\n",
    "print(response.content)\n",
    "\n",
    "# 假设小明提供了反馈\n",
    "user_feedback = \"我觉得这个服务很好，界面友好，使用方便！\"\n",
    "# 打印小明提供了反馈\n",
    "print(\"小明提供的反馈:\")\n",
    "print(user_feedback)\n",
    "# 将用户反馈传递给聊天模型\n",
    "feedback_prompt = f\"{formatted_prompt}\\n用户反馈: {user_feedback}\"\n",
    "response_feedback = chat([HumanMessage(content=feedback_prompt)])\n",
    "\n",
    "# 打印模型对用户反馈的回复\n",
    "print(\"模型对用户反馈的回复:\")\n",
    "print(response_feedback.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的回复:\n",
      "1924年10月20日并不是一个特别著名的物理学事件的具体日期，但这一年确实有一个非常重要的物理学贡献值得一提，那就是路易·德布罗意（Louis de Broglie）提出了物质波的概念。虽然确切的提出日期不一定是10月20日，但这个理论对量子力学的发展产生了深远的影响。\n",
      "\n",
      "### 背景\n",
      "\n",
      "在20世纪初，物理学家们已经认识到光不仅具有波动性（如干涉和衍射现象所显示的），而且还有粒子性（例如光电效应）。这一发现导致了光的波粒二象性的概念。然而，对于物质粒子（如电子、质子等），当时的主流观点是它们仅表现出粒子性质。\n",
      "\n",
      "### 德布罗意的物质波假说\n",
      "\n",
      "1924年，法国物理学家路易·德布罗意在他的博士论文中提出了一项革命性的假设：如果光可以同时被视为波和粒子，那么物质粒子也应该具有类似的双重性质。他推测，所有物质都可能具有波动性，这种波动性的波长与其动量成反比。这个关系后来被称为德布罗意关系式，表达为：\n",
      "\n",
      "\\[ \\lambda = \\frac{h}{p} \\]\n",
      "\n",
      "其中，\\(\\lambda\\) 是波长，\\(h\\) 是普朗克常数，\\(p\\) 是粒子的动量。\n",
      "\n",
      "### 影响与验证\n",
      "\n",
      "德布罗意的理论最初并未得到广泛接受，但它为量子力学的发展奠定了基础。1927年，克莱德·戴维森（Clyde Davisson）和莱斯特·革末（Lester Germer）通过实验观察到了电子的衍射现象，这直接证实了德布罗意关于物质波的预言。这些实验结果进一步支持了量子力学的基本原理，并为德布罗意赢得了1929年的诺贝尔物理学奖。\n",
      "\n",
      "德布罗意的物质波理论不仅改变了我们对物质本质的理解，还促进了量子力学的快速发展，对后续的科学研究和技术应用产生了深远影响，包括量子计算、纳米技术和半导体技术等领域。\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chat_models import ChatTongyi\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 初始化聊天模型\n",
    "chat = ChatTongyi(\n",
    "    model='qwen-plus',\n",
    "    top_p=0.9,\n",
    "    temperature=0.9,\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "# 自定义函数，获取100年前的日期\n",
    "def date_100_years_ago():\n",
    "    today = datetime.now()\n",
    "    years_ago = today - relativedelta(years=100)\n",
    "    return years_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate(\n",
    "    template=\"给我讲一个 {adjective} 案例，在时间 {date}\",\n",
    "    input_variables=[\"adjective\"],\n",
    "    partial_variables={\"date\": date_100_years_ago()}  # 使用函数\n",
    ")\n",
    "\n",
    "# 格式化提示\n",
    "formatted_prompt = prompt.format(adjective=\"物理学\")\n",
    "\n",
    "# 将格式化后的提示包装为 HumanMessage，并传递给 chat()\n",
    "response = chat([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "# 打印模型的回复\n",
    "print(\"模型的回复:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 100 轮训练，损失值: 1.3410\n",
      "第 200 轮训练，损失值: 1.2858\n",
      "第 300 轮训练，损失值: 1.2713\n",
      "第 400 轮训练，损失值: 1.2451\n",
      "第 500 轮训练，损失值: 1.2457\n",
      "第 600 轮训练，损失值: 1.1208\n",
      "第 700 轮训练，损失值: 0.7729\n",
      "第 800 轮训练，损失值: 0.6330\n",
      "第 900 轮训练，损失值: 0.4212\n",
      "第 1000 轮训练，损失值: 0.3442\n",
      "第 1100 轮训练，损失值: 0.2896\n",
      "第 1200 轮训练，损失值: 0.5040\n",
      "第 1300 轮训练，损失值: 0.2432\n",
      "第 1400 轮训练，损失值: 0.1168\n",
      "第 1500 轮训练，损失值: 0.0639\n",
      "第 1600 轮训练，损失值: 0.1916\n",
      "第 1700 轮训练，损失值: 0.1238\n",
      "第 1800 轮训练，损失值: 0.0782\n",
      "第 1900 轮训练，损失值: 0.0802\n",
      "第 2000 轮训练，损失值: 0.8418\n",
      "第 2100 轮训练，损失值: 0.7855\n",
      "第 2200 轮训练，损失值: 1.6156\n",
      "第 2300 轮训练，损失值: 0.7280\n",
      "第 2400 轮训练，损失值: 0.4674\n",
      "第 2500 轮训练，损失值: 1.4545\n",
      "第 2600 轮训练，损失值: 1.2642\n",
      "第 2700 轮训练，损失值: 0.5981\n",
      "第 2800 轮训练，损失值: 0.3212\n",
      "第 2900 轮训练，损失值: 0.2597\n",
      "第 3000 轮训练，损失值: 0.2326\n",
      "第 3100 轮训练，损失值: 0.1948\n",
      "第 3200 轮训练，损失值: 0.2026\n",
      "第 3300 轮训练，损失值: 0.1994\n",
      "第 3400 轮训练，损失值: 0.1926\n",
      "第 3500 轮训练，损失值: 0.1820\n",
      "第 3600 轮训练，损失值: 0.1648\n",
      "第 3700 轮训练，损失值: 0.1438\n",
      "第 3800 轮训练，损失值: 0.1260\n",
      "第 3900 轮训练，损失值: 0.1120\n",
      "第 4000 轮训练，损失值: 0.1010\n",
      "第 4100 轮训练，损失值: 0.0919\n",
      "第 4200 轮训练，损失值: 0.0841\n",
      "第 4300 轮训练，损失值: 0.0779\n",
      "第 4400 轮训练，损失值: 0.0736\n",
      "第 4500 轮训练，损失值: 0.0716\n",
      "第 4600 轮训练，损失值: 0.0728\n",
      "第 4700 轮训练，损失值: 0.0788\n",
      "第 4800 轮训练，损失值: 0.0904\n",
      "第 4900 轮训练，损失值: 0.1040\n",
      "第 5000 轮训练，损失值: 0.1060\n",
      "第 5100 轮训练，损失值: 0.0936\n",
      "第 5200 轮训练，损失值: 0.0770\n",
      "第 5300 轮训练，损失值: 0.0617\n",
      "第 5400 轮训练，损失值: 0.0502\n",
      "第 5500 轮训练，损失值: 0.0419\n",
      "第 5600 轮训练，损失值: 0.0359\n",
      "第 5700 轮训练，损失值: 0.0315\n",
      "第 5800 轮训练，损失值: 0.0286\n",
      "第 5900 轮训练，损失值: 0.0268\n",
      "第 6000 轮训练，损失值: 0.0259\n",
      "第 6100 轮训练，损失值: 0.0262\n",
      "第 6200 轮训练，损失值: 0.0279\n",
      "第 6300 轮训练，损失值: 0.0332\n",
      "第 6400 轮训练，损失值: 0.0564\n",
      "第 6500 轮训练，损失值: 1.2157\n",
      "第 6600 轮训练，损失值: 0.0958\n",
      "第 6700 轮训练，损失值: 0.0597\n",
      "第 6800 轮训练，损失值: 0.0453\n",
      "第 6900 轮训练，损失值: 0.0395\n",
      "第 7000 轮训练，损失值: 0.0357\n",
      "第 7100 轮训练，损失值: 0.0338\n",
      "第 7200 轮训练，损失值: 0.0338\n",
      "第 7300 轮训练，损失值: 0.0349\n",
      "第 7400 轮训练，损失值: 0.0361\n",
      "第 7500 轮训练，损失值: 0.0368\n",
      "第 7600 轮训练，损失值: 0.0390\n",
      "第 7700 轮训练，损失值: 0.0421\n",
      "第 7800 轮训练，损失值: 0.0461\n",
      "第 7900 轮训练，损失值: 0.0574\n",
      "第 8000 轮训练，损失值: 0.0593\n",
      "第 8100 轮训练，损失值: 0.0952\n",
      "第 8200 轮训练，损失值: 0.0874\n",
      "第 8300 轮训练，损失值: 0.0695\n",
      "第 8400 轮训练，损失值: 0.0537\n",
      "第 8500 轮训练，损失值: 0.0421\n",
      "第 8600 轮训练，损失值: 0.0342\n",
      "第 8700 轮训练，损失值: 0.0300\n",
      "第 8800 轮训练，损失值: 0.0779\n",
      "第 8900 轮训练，损失值: 0.0660\n",
      "第 9000 轮训练，损失值: 0.0358\n",
      "第 9100 轮训练，损失值: 0.0249\n",
      "第 9200 轮训练，损失值: 0.0219\n",
      "第 9300 轮训练，损失值: 0.0213\n",
      "第 9400 轮训练，损失值: 0.0429\n",
      "第 9500 轮训练，损失值: 0.0233\n",
      "第 9600 轮训练，损失值: 0.0154\n",
      "第 9700 轮训练，损失值: 0.0716\n",
      "第 9800 轮训练，损失值: 0.0160\n",
      "第 9900 轮训练，损失值: 0.0165\n",
      "第 10000 轮训练，损失值: 0.0142\n",
      "第 10100 轮训练，损失值: 0.0106\n",
      "第 10200 轮训练，损失值: 0.0079\n",
      "第 10300 轮训练，损失值: 0.0062\n",
      "第 10400 轮训练，损失值: 0.0052\n",
      "第 10500 轮训练，损失值: 0.0045\n",
      "第 10600 轮训练，损失值: 0.0041\n",
      "第 10700 轮训练，损失值: 0.0038\n",
      "第 10800 轮训练，损失值: 0.0036\n",
      "第 10900 轮训练，损失值: 0.0034\n",
      "第 11000 轮训练，损失值: 0.0033\n",
      "第 11100 轮训练，损失值: 0.0032\n",
      "第 11200 轮训练，损失值: 0.0032\n",
      "第 11300 轮训练，损失值: 0.0033\n",
      "第 11400 轮训练，损失值: 0.0042\n",
      "第 11500 轮训练，损失值: 0.0052\n",
      "第 11600 轮训练，损失值: 0.0051\n",
      "第 11700 轮训练，损失值: 0.0048\n",
      "第 11800 轮训练，损失值: 0.0044\n",
      "第 11900 轮训练，损失值: 0.0051\n",
      "第 12000 轮训练，损失值: 0.0055\n",
      "第 12100 轮训练，损失值: 0.0048\n",
      "第 12200 轮训练，损失值: 0.0040\n",
      "第 12300 轮训练，损失值: 0.0033\n",
      "第 12400 轮训练，损失值: 0.0027\n",
      "第 12500 轮训练，损失值: 0.0024\n",
      "第 12600 轮训练，损失值: 0.0020\n",
      "第 12700 轮训练，损失值: 0.0017\n",
      "第 12800 轮训练，损失值: 0.0014\n",
      "第 12900 轮训练，损失值: 0.0012\n",
      "第 13000 轮训练，损失值: 0.0011\n",
      "第 13100 轮训练，损失值: 0.0010\n",
      "第 13200 轮训练，损失值: 0.0008\n",
      "第 13300 轮训练，损失值: 0.0005\n",
      "第 13400 轮训练，损失值: 0.0004\n",
      "第 13500 轮训练，损失值: 0.0003\n",
      "第 13600 轮训练，损失值: 0.0003\n",
      "第 13700 轮训练，损失值: 0.0002\n",
      "第 13800 轮训练，损失值: 0.0002\n",
      "第 13900 轮训练，损失值: 0.0002\n",
      "第 14000 轮训练，损失值: 0.0002\n",
      "第 14100 轮训练，损失值: 0.0002\n",
      "第 14200 轮训练，损失值: 0.0003\n",
      "第 14300 轮训练，损失值: 0.0003\n",
      "第 14400 轮训练，损失值: 0.0003\n",
      "第 14500 轮训练，损失值: 0.0003\n",
      "第 14600 轮训练，损失值: 0.0003\n",
      "第 14700 轮训练，损失值: 0.0002\n",
      "第 14800 轮训练，损失值: 0.0002\n",
      "第 14900 轮训练，损失值: 0.0002\n",
      "第 15000 轮训练，损失值: 0.0002\n",
      "第 15100 轮训练，损失值: 0.0002\n",
      "第 15200 轮训练，损失值: 0.0002\n",
      "第 15300 轮训练，损失值: 0.0002\n",
      "第 15400 轮训练，损失值: 0.0002\n",
      "第 15500 轮训练，损失值: 0.0002\n",
      "第 15600 轮训练，损失值: 0.0002\n",
      "第 15700 轮训练，损失值: 0.0001\n",
      "第 15800 轮训练，损失值: 0.0001\n",
      "第 15900 轮训练，损失值: 0.0001\n",
      "第 16000 轮训练，损失值: 0.0001\n",
      "第 16100 轮训练，损失值: 0.0001\n",
      "第 16200 轮训练，损失值: 0.0002\n",
      "第 16300 轮训练，损失值: 0.0004\n",
      "第 16400 轮训练，损失值: 0.0026\n",
      "第 16500 轮训练，损失值: 0.0084\n",
      "第 16600 轮训练，损失值: 0.0436\n",
      "第 16700 轮训练，损失值: 3.5507\n",
      "第 16800 轮训练，损失值: 15.4866\n",
      "第 16900 轮训练，损失值: 10.9706\n",
      "第 17000 轮训练，损失值: 11.6296\n",
      "第 17100 轮训练，损失值: 7.2326\n",
      "第 17200 轮训练，损失值: 4.8252\n",
      "第 17300 轮训练，损失值: 3.6831\n",
      "第 17400 轮训练，损失值: 3.3099\n",
      "第 17500 轮训练，损失值: 1.5280\n",
      "第 17600 轮训练，损失值: 1.1054\n",
      "第 17700 轮训练，损失值: 0.8377\n",
      "第 17800 轮训练，损失值: 0.4867\n",
      "第 17900 轮训练，损失值: 0.4469\n",
      "第 18000 轮训练，损失值: 0.5248\n",
      "第 18100 轮训练，损失值: 0.9182\n",
      "第 18200 轮训练，损失值: 0.3733\n",
      "第 18300 轮训练，损失值: 0.3359\n",
      "第 18400 轮训练，损失值: 0.4881\n",
      "第 18500 轮训练，损失值: 0.7590\n",
      "第 18600 轮训练，损失值: 0.3915\n",
      "第 18700 轮训练，损失值: 0.4505\n",
      "第 18800 轮训练，损失值: 0.4362\n",
      "第 18900 轮训练，损失值: 0.3101\n",
      "第 19000 轮训练，损失值: 0.4242\n",
      "第 19100 轮训练，损失值: 0.4253\n",
      "第 19200 轮训练，损失值: 0.3843\n",
      "第 19300 轮训练，损失值: 0.3490\n",
      "第 19400 轮训练，损失值: 0.3272\n",
      "第 19500 轮训练，损失值: 0.3363\n",
      "第 19600 轮训练，损失值: 0.1372\n",
      "第 19700 轮训练，损失值: 0.5052\n",
      "第 19800 轮训练，损失值: 0.4918\n",
      "第 19900 轮训练，损失值: 0.4790\n",
      "第 20000 轮训练，损失值: 0.4681\n",
      "第 20100 轮训练，损失值: 0.4596\n",
      "第 20200 轮训练，损失值: 0.4529\n",
      "第 20300 轮训练，损失值: 0.4478\n",
      "第 20400 轮训练，损失值: 0.4436\n",
      "第 20500 轮训练，损失值: 0.4401\n",
      "第 20600 轮训练，损失值: 0.4369\n",
      "第 20700 轮训练，损失值: 0.4339\n",
      "第 20800 轮训练，损失值: 0.4310\n",
      "第 20900 轮训练，损失值: 0.4279\n",
      "第 21000 轮训练，损失值: 0.4246\n",
      "第 21100 轮训练，损失值: 0.4210\n",
      "第 21200 轮训练，损失值: 0.4168\n",
      "第 21300 轮训练，损失值: 0.4120\n",
      "第 21400 轮训练，损失值: 0.4062\n",
      "第 21500 轮训练，损失值: 0.3991\n",
      "第 21600 轮训练，损失值: 0.3902\n",
      "第 21700 轮训练，损失值: 0.3784\n",
      "第 21800 轮训练，损失值: 0.3626\n",
      "第 21900 轮训练，损失值: 0.3426\n",
      "第 22000 轮训练，损失值: 0.3207\n",
      "第 22100 轮训练，损失值: 0.3001\n",
      "第 22200 轮训练，损失值: 0.2820\n",
      "第 22300 轮训练，损失值: 0.2660\n",
      "第 22400 轮训练，损失值: 0.2513\n",
      "第 22500 轮训练，损失值: 0.2372\n",
      "第 22600 轮训练，损失值: 0.2223\n",
      "第 22700 轮训练，损失值: 0.2032\n",
      "第 22800 轮训练，损失值: 0.1753\n",
      "第 22900 轮训练，损失值: 0.1499\n",
      "第 23000 轮训练，损失值: 12.6387\n",
      "第 23100 轮训练，损失值: 9.8639\n",
      "第 23200 轮训练，损失值: 5.5671\n",
      "第 23300 轮训练，损失值: 7.0941\n",
      "第 23400 轮训练，损失值: 8.4795\n",
      "第 23500 轮训练，损失值: 5.5317\n",
      "第 23600 轮训练，损失值: 4.0507\n",
      "第 23700 轮训练，损失值: 3.2582\n",
      "第 23800 轮训练，损失值: 2.7880\n",
      "第 23900 轮训练，损失值: 2.4127\n",
      "第 24000 轮训练，损失值: 2.2690\n",
      "第 24100 轮训练，损失值: 1.6994\n",
      "第 24200 轮训练，损失值: 0.5555\n",
      "第 24300 轮训练，损失值: 0.2973\n",
      "第 24400 轮训练，损失值: 0.2154\n",
      "第 24500 轮训练，损失值: 0.1735\n",
      "第 24600 轮训练，损失值: 0.1457\n",
      "第 24700 轮训练，损失值: 0.1255\n",
      "第 24800 轮训练，损失值: 0.1100\n",
      "第 24900 轮训练，损失值: 0.0977\n",
      "第 25000 轮训练，损失值: 0.0878\n",
      "第 25100 轮训练，损失值: 0.0797\n",
      "第 25200 轮训练，损失值: 0.0732\n",
      "第 25300 轮训练，损失值: 0.0679\n",
      "第 25400 轮训练，损失值: 0.0635\n",
      "第 25500 轮训练，损失值: 0.0596\n",
      "第 25600 轮训练，损失值: 0.0561\n",
      "第 25700 轮训练，损失值: 0.0528\n",
      "第 25800 轮训练，损失值: 0.0498\n",
      "第 25900 轮训练，损失值: 0.0470\n",
      "第 26000 轮训练，损失值: 0.0443\n",
      "第 26100 轮训练，损失值: 0.0417\n",
      "第 26200 轮训练，损失值: 0.0394\n",
      "第 26300 轮训练，损失值: 0.0371\n",
      "第 26400 轮训练，损失值: 0.0350\n",
      "第 26500 轮训练，损失值: 0.0329\n",
      "第 26600 轮训练，损失值: 0.0310\n",
      "第 26700 轮训练，损失值: 0.0292\n",
      "第 26800 轮训练，损失值: 0.0275\n",
      "第 26900 轮训练，损失值: 0.0258\n",
      "第 27000 轮训练，损失值: 0.0243\n",
      "第 27100 轮训练，损失值: 0.0228\n",
      "第 27200 轮训练，损失值: 0.0214\n",
      "第 27300 轮训练，损失值: 0.0200\n",
      "第 27400 轮训练，损失值: 0.0188\n",
      "第 27500 轮训练，损失值: 0.0176\n",
      "第 27600 轮训练，损失值: 0.0164\n",
      "第 27700 轮训练，损失值: 0.0154\n",
      "第 27800 轮训练，损失值: 0.0144\n",
      "第 27900 轮训练，损失值: 0.0135\n",
      "第 28000 轮训练，损失值: 0.0127\n",
      "第 28100 轮训练，损失值: 0.0120\n",
      "第 28200 轮训练，损失值: 0.0114\n",
      "第 28300 轮训练，损失值: 0.0109\n",
      "第 28400 轮训练，损失值: 0.0105\n",
      "第 28500 轮训练，损失值: 0.0102\n",
      "第 28600 轮训练，损失值: 0.0099\n",
      "第 28700 轮训练，损失值: 0.0095\n",
      "第 28800 轮训练，损失值: 0.0090\n",
      "第 28900 轮训练，损失值: 0.0086\n",
      "第 29000 轮训练，损失值: 0.0081\n",
      "第 29100 轮训练，损失值: 0.0078\n",
      "第 29200 轮训练，损失值: 0.0074\n",
      "第 29300 轮训练，损失值: 0.0071\n",
      "第 29400 轮训练，损失值: 0.0069\n",
      "第 29500 轮训练，损失值: 0.0067\n",
      "第 29600 轮训练，损失值: 0.0067\n",
      "第 29700 轮训练，损失值: 0.0072\n",
      "第 29800 轮训练，损失值: 0.0050\n",
      "第 29900 轮训练，损失值: 0.0046\n",
      "第 30000 轮训练，损失值: 0.0043\n",
      "第 30100 轮训练，损失值: 0.0039\n",
      "第 30200 轮训练，损失值: 0.0036\n",
      "第 30300 轮训练，损失值: 0.0034\n",
      "第 30400 轮训练，损失值: 0.0031\n",
      "第 30500 轮训练，损失值: 0.0029\n",
      "第 30600 轮训练，损失值: 0.0028\n",
      "第 30700 轮训练，损失值: 0.0026\n",
      "第 30800 轮训练，损失值: 0.0024\n",
      "第 30900 轮训练，损失值: 0.0023\n",
      "第 31000 轮训练，损失值: 0.0021\n",
      "第 31100 轮训练，损失值: 0.0019\n",
      "第 31200 轮训练，损失值: 0.0017\n",
      "第 31300 轮训练，损失值: 0.0016\n",
      "第 31400 轮训练，损失值: 0.0018\n",
      "第 31500 轮训练，损失值: 0.0031\n",
      "第 31600 轮训练，损失值: 0.0444\n",
      "第 31700 轮训练，损失值: 0.0116\n",
      "第 31800 轮训练，损失值: 0.0092\n",
      "第 31900 轮训练，损失值: 0.0079\n",
      "第 32000 轮训练，损失值: 0.0070\n",
      "第 32100 轮训练，损失值: 0.0072\n",
      "第 32200 轮训练，损失值: 0.2202\n",
      "第 32300 轮训练，损失值: 0.2174\n",
      "第 32400 轮训练，损失值: 0.2151\n",
      "第 32500 轮训练，损失值: 0.2128\n",
      "第 32600 轮训练，损失值: 0.2106\n",
      "第 32700 轮训练，损失值: 0.2083\n",
      "第 32800 轮训练，损失值: 0.2060\n",
      "第 32900 轮训练，损失值: 0.2036\n",
      "第 33000 轮训练，损失值: 0.2012\n",
      "第 33100 轮训练，损失值: 0.1987\n",
      "第 33200 轮训练，损失值: 0.1960\n",
      "第 33300 轮训练，损失值: 0.1933\n",
      "第 33400 轮训练，损失值: 0.1905\n",
      "第 33500 轮训练，损失值: 0.1876\n",
      "第 33600 轮训练，损失值: 0.1846\n",
      "第 33700 轮训练，损失值: 0.1814\n",
      "第 33800 轮训练，损失值: 0.1782\n",
      "第 33900 轮训练，损失值: 0.1748\n",
      "第 34000 轮训练，损失值: 0.1713\n",
      "第 34100 轮训练，损失值: 0.1677\n",
      "第 34200 轮训练，损失值: 0.1640\n",
      "第 34300 轮训练，损失值: 0.1602\n",
      "第 34400 轮训练，损失值: 0.1562\n",
      "第 34500 轮训练，损失值: 0.1521\n",
      "第 34600 轮训练，损失值: 0.1479\n",
      "第 34700 轮训练，损失值: 0.1434\n",
      "第 34800 轮训练，损失值: 0.1388\n",
      "第 34900 轮训练，损失值: 0.1337\n",
      "第 35000 轮训练，损失值: 0.1281\n",
      "第 35100 轮训练，损失值: 0.1212\n",
      "第 35200 轮训练，损失值: 0.1115\n",
      "第 35300 轮训练，损失值: 0.0996\n",
      "第 35400 轮训练，损失值: 0.0907\n",
      "第 35500 轮训练，损失值: 0.0845\n",
      "第 35600 轮训练，损失值: 0.0740\n",
      "第 35700 轮训练，损失值: 0.0495\n",
      "第 35800 轮训练，损失值: 0.0070\n",
      "第 35900 轮训练，损失值: 0.0042\n",
      "第 36000 轮训练，损失值: 0.0034\n",
      "第 36100 轮训练，损失值: 0.0033\n",
      "第 36200 轮训练，损失值: 0.0032\n",
      "第 36300 轮训练，损失值: 0.0027\n",
      "第 36400 轮训练，损失值: 0.0010\n",
      "第 36500 轮训练，损失值: 0.0009\n",
      "第 36600 轮训练，损失值: 0.0008\n",
      "第 36700 轮训练，损失值: 0.0007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 592\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# 主程序\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# 示例生成\u001b[39;00m\n\u001b[1;32m    595\u001b[0m     seed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m你好\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 556\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    554\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 556\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m第 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 轮训练，损失值: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 516\u001b[0m, in \u001b[0;36mLanguageModelTrainer.train\u001b[0;34m(self, inputs, targets, h0, grad_clip)\u001b[0m\n\u001b[1;32m    514\u001b[0m dloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_func\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    515\u001b[0m dh_n \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros_like(h) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m h_n]\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdh_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# 裁剪梯度\u001b[39;00m\n\u001b[1;32m    519\u001b[0m clipped_gradients \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mclip(grad, \u001b[38;5;241m-\u001b[39mgrad_clip, grad_clip) \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgradients]\n",
      "Cell \u001b[0;32mIn[13], line 485\u001b[0m, in \u001b[0;36mLanguageModel.backward\u001b[0;34m(self, doutputs, dh_n)\u001b[0m\n\u001b[1;32m    483\u001b[0m d_rnn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mbackward(doutputs)\n\u001b[1;32m    484\u001b[0m d_rnn_outputs \u001b[38;5;241m=\u001b[39m d_rnn_outputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 485\u001b[0m d_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_rnn_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdh_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m d_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mbackward(d_embeddings)\n",
      "Cell \u001b[0;32mIn[13], line 239\u001b[0m, in \u001b[0;36mRNNLayer.backward\u001b[0;34m(self, doutputs, dh_n, grad_clip)\u001b[0m\n\u001b[1;32m    237\u001b[0m rnn_cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_cells[i]\n\u001b[1;32m    238\u001b[0m dh \u001b[38;5;241m=\u001b[39m dh \u001b[38;5;241m+\u001b[39m dh_next[i]\n\u001b[0;32m--> 239\u001b[0m dx_step, dh_prev \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_cell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m dh_next[i] \u001b[38;5;241m=\u001b[39m dh_prev\n\u001b[1;32m    241\u001b[0m dh \u001b[38;5;241m=\u001b[39m dx_step  \u001b[38;5;66;03m# 当前层的 dx_step 作为上一层的 dh\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 156\u001b[0m, in \u001b[0;36mRNNCell.backward\u001b[0;34m(self, dh_next, grad_clip)\u001b[0m\n\u001b[1;32m    154\u001b[0m dW_ih \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(dW_ih, \u001b[38;5;241m-\u001b[39mgrad_clip, grad_clip)\n\u001b[1;32m    155\u001b[0m dW_hh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(dW_hh, \u001b[38;5;241m-\u001b[39mgrad_clip, grad_clip)\n\u001b[0;32m--> 156\u001b[0m db_h \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mgrad_clip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# 计算对输入和前一隐藏状态的梯度\u001b[39;00m\n\u001b[1;32m    159\u001b[0m dx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_ih\u001b[38;5;241m.\u001b[39mT, dtanh_h)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mclip\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/chatchat/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2180\u001b[0m, in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip\u001b[39m(a, a_min, a_max, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2178\u001b[0m \n\u001b[1;32m   2179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chatchat/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/chatchat/lib/python3.8/site-packages/numpy/core/_methods.py:139\u001b[0m, in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    138\u001b[0m     using_deprecated_nan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_clip_dep_is_scalar_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m     using_deprecated_nan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/chatchat/lib/python3.8/site-packages/numpy/core/_methods.py:95\u001b[0m, in \u001b[0;36m_clip_dep_is_scalar_nan\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_clip_dep_is_scalar_nan\u001b[39m(a):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfromnumeric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ndim\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim(a) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
