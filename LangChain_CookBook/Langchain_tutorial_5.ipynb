{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chat_models import ChatTongyi\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 初始化聊天模型\n",
    "chat = ChatTongyi(\n",
    "    model='qwen-plus',\n",
    "    top_p=0.9,\n",
    "    temperature=0.9,\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "# 创建部分提示模板\n",
    "partial_prompt = PromptTemplate(\n",
    "    template=\"{greeting} {name}，我们很高兴您使用我们的服务。请您分享一下您的使用体验如何？\",\n",
    "    input_variables=[\"name\"],\n",
    "    partial_variables={\"greeting\": \"亲爱的用户\"}\n",
    ")\n",
    "\n",
    "# 格式化提示\n",
    "input_name = \"小明\"\n",
    "formatted_prompt = partial_prompt.format(name=input_name)\n",
    "\n",
    "# 将格式化后的提示包装为 HumanMessage，并传递给 chat()\n",
    "response = chat([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "# 打印模型的初始回复\n",
    "print(\"模型的问候:\")\n",
    "print(response.content)\n",
    "\n",
    "# 假设小明提供了反馈\n",
    "user_feedback = \"我觉得这个服务很好，界面友好，使用方便！\"\n",
    "# 打印小明提供了反馈\n",
    "print(\"小明提供的反馈:\")\n",
    "print(user_feedback)\n",
    "# 将用户反馈传递给聊天模型\n",
    "feedback_prompt = f\"{formatted_prompt}\\n用户反馈: {user_feedback}\"\n",
    "response_feedback = chat([HumanMessage(content=feedback_prompt)])\n",
    "\n",
    "# 打印模型对用户反馈的回复\n",
    "print(\"模型对用户反馈的回复:\")\n",
    "print(response_feedback.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chat_models import ChatTongyi\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 初始化聊天模型\n",
    "chat = ChatTongyi(\n",
    "    model='qwen-plus',\n",
    "    top_p=0.9,\n",
    "    temperature=0.9,\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "# 自定义函数，获取100年前的日期\n",
    "def date_100_years_ago():\n",
    "    today = datetime.now()\n",
    "    years_ago = today - relativedelta(years=100)\n",
    "    return years_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate(\n",
    "    template=\"给我讲一个 {adjective} 案例，在时间 {date}\",\n",
    "    input_variables=[\"adjective\"],\n",
    "    partial_variables={\"date\": date_100_years_ago()}  # 使用函数\n",
    ")\n",
    "\n",
    "# 格式化提示\n",
    "formatted_prompt = prompt.format(adjective=\"物理学\")\n",
    "\n",
    "# 将格式化后的提示包装为 HumanMessage，并传递给 chat()\n",
    "response = chat([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "# 打印模型的回复\n",
    "print(\"模型的回复:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
